<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Usage &#8212; createllm 0.1.8 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/basic.css?v=686e5160" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=27fed22d" />
    <script src="_static/documentation_options.js?v=22607128"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="usage">
<h1>Usage<a class="headerlink" href="#usage" title="Link to this heading">¶</a></h1>
<section id="usage-guide">
<h2>Usage Guide<a class="headerlink" href="#usage-guide" title="Link to this heading">¶</a></h2>
<p>This guide will walk you through the main features and usage patterns of createllm.</p>
<section id="basic-usage">
<h3>Basic Usage<a class="headerlink" href="#basic-usage" title="Link to this heading">¶</a></h3>
<section id="prepare-your-data">
<h4>1. Prepare Your Data<a class="headerlink" href="#prepare-your-data" title="Link to this heading">¶</a></h4>
<p>First, prepare your training data in a text file:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># my_training_data.txt</span>
<span class="n">This</span> <span class="ow">is</span> <span class="n">your</span> <span class="n">training</span> <span class="n">data</span><span class="o">.</span>
<span class="n">It</span> <span class="n">can</span> <span class="n">contain</span> <span class="n">multiple</span> <span class="n">lines</span><span class="o">.</span>
<span class="n">The</span> <span class="n">model</span> <span class="n">will</span> <span class="n">learn</span> <span class="kn">from</span><span class="w"> </span><span class="nn">this</span> <span class="n">text</span><span class="o">.</span>
</pre></div>
</div>
</section>
<section id="initialize-the-text-processor">
<h4>2. Initialize the Text Processor<a class="headerlink" href="#initialize-the-text-processor" title="Link to this heading">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">createllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">TextFileProcessor</span>

<span class="c1"># Initialize processor with your data file</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">TextFileProcessor</span><span class="p">(</span><span class="s2">&quot;my_training_data.txt&quot;</span><span class="p">)</span>

<span class="c1"># Read the text file</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">read_file</span><span class="p">()</span>

<span class="c1"># Tokenize the text</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">encode</span><span class="p">,</span> <span class="n">decode</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="configure-your-model">
<h4>3. Configure Your Model<a class="headerlink" href="#configure-your-model" title="Link to this heading">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">createllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelConfig</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">ModelConfig</span><span class="p">(</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>  <span class="c1"># From tokenization</span>
    <span class="n">n_embd</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span>            <span class="c1"># Embedding dimension</span>
    <span class="n">block_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>        <span class="c1"># Context window size</span>
    <span class="n">n_layer</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>             <span class="c1"># Number of transformer layers</span>
    <span class="n">n_head</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>              <span class="c1"># Number of attention heads</span>
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span>            <span class="c1"># Dropout rate</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="create-and-train-the-model">
<h4>4. Create and Train the Model<a class="headerlink" href="#create-and-train-the-model" title="Link to this heading">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">createllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">GPTLanguageModel</span><span class="p">,</span> <span class="n">GPTTrainer</span>

<span class="c1"># Initialize the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPTLanguageModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model initialized with </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">n_params</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1e6</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">M parameters&quot;</span><span class="p">)</span>

<span class="c1"># Initialize the trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">GPTTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">train_data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
    <span class="n">val_data</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">gradient_clip</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">1000</span>
<span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">save_dir</span><span class="o">=</span><span class="s1">&#39;checkpoints&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="generate-text">
<h4>5. Generate Text<a class="headerlink" href="#generate-text" title="Link to this heading">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate text</span>
<span class="n">context</span> <span class="o">=</span> <span class="s2">&quot;Once upon a time&quot;</span>
<span class="n">context_tokens</span> <span class="o">=</span> <span class="n">encode</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
<span class="n">context_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">context_tokens</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">generated</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">context_tensor</span><span class="p">,</span>
    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">top_k</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
    <span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.2</span>
<span class="p">)</span>

<span class="c1"># Decode and print the generated text</span>
<span class="n">generated_text</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">generated</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Generated text:</span><span class="se">\n</span><span class="si">{</span><span class="n">generated_text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="advanced-usage">
<h3>Advanced Usage<a class="headerlink" href="#advanced-usage" title="Link to this heading">¶</a></h3>
<section id="custom-model-configuration">
<h4>1. Custom Model Configuration<a class="headerlink" href="#custom-model-configuration" title="Link to this heading">¶</a></h4>
<p>You can customize the model architecture based on your needs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Larger model for better understanding</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">ModelConfig</span><span class="p">(</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
    <span class="n">n_embd</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>      <span class="c1"># Larger embedding dimension</span>
    <span class="n">block_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>  <span class="c1"># Longer context window</span>
    <span class="n">n_layer</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>       <span class="c1"># More transformer layers</span>
    <span class="n">n_head</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>        <span class="c1"># More attention heads</span>
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span>      <span class="c1"># Lower dropout for larger models</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="advanced-training-options">
<h4>2. Advanced Training Options<a class="headerlink" href="#advanced-training-options" title="Link to this heading">¶</a></h4>
<p>Customize the training process:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GPTTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">train_data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
    <span class="n">val_data</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>     <span class="c1"># Smaller batch size for memory efficiency</span>
    <span class="n">gradient_clip</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="c1"># Prevent gradient explosion</span>
    <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">1000</span>  <span class="c1"># Learning rate warmup</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="advanced-text-generation">
<h4>3. Advanced Text Generation<a class="headerlink" href="#advanced-text-generation" title="Link to this heading">¶</a></h4>
<p>Control text generation with various parameters:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">generated</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">context_tensor</span><span class="p">,</span>
    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>      <span class="c1"># Generate more tokens</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>         <span class="c1"># Lower temperature for more focused output</span>
    <span class="n">top_k</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>               <span class="c1"># Limit sampling to top 40 tokens</span>
    <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>             <span class="c1"># Nucleus sampling threshold</span>
    <span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.5</span>   <span class="c1"># Stronger penalty for repetition</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="model-checkpointing">
<h4>4. Model Checkpointing<a class="headerlink" href="#model-checkpointing" title="Link to this heading">¶</a></h4>
<p>Save and load model checkpoints:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Save model</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">&quot;checkpoints/model.pt&quot;</span><span class="p">)</span>

<span class="c1"># Load model</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;checkpoints/model.pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="best-practices">
<h3>Best Practices<a class="headerlink" href="#best-practices" title="Link to this heading">¶</a></h3>
<section id="data-preparation">
<h4>1. Data Preparation<a class="headerlink" href="#data-preparation" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Clean your training data thoroughly</p></li>
<li><p>Remove irrelevant content</p></li>
<li><p>Ensure consistent formatting</p></li>
<li><p>Consider data augmentation for small datasets</p></li>
</ul>
</section>
<section id="model-configuration">
<h4>2. Model Configuration<a class="headerlink" href="#model-configuration" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Start with a smaller model for quick experiments</p></li>
<li><p>Increase model size gradually</p></li>
<li><p>Monitor validation loss to prevent overfitting</p></li>
<li><p>Use appropriate dropout rates</p></li>
</ul>
</section>
<section id="training-process">
<h4>3. Training Process<a class="headerlink" href="#training-process" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Use learning rate warmup</p></li>
<li><p>Monitor training and validation losses</p></li>
<li><p>Save best model checkpoints</p></li>
<li><p>Use early stopping if needed</p></li>
</ul>
</section>
<section id="text-generation">
<h4>4. Text Generation<a class="headerlink" href="#text-generation" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Experiment with different temperature values</p></li>
<li><p>Use top-k and top-p sampling for better quality</p></li>
<li><p>Adjust repetition penalty based on output quality</p></li>
<li><p>Consider using beam search for better coherence</p></li>
</ul>
</section>
</section>
<section id="example-use-cases">
<h3>Example Use Cases<a class="headerlink" href="#example-use-cases" title="Link to this heading">¶</a></h3>
<section id="domain-specific-documentation">
<h4>1. Domain-Specific Documentation<a class="headerlink" href="#domain-specific-documentation" title="Link to this heading">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train on technical documentation</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">TextFileProcessor</span><span class="p">(</span><span class="s2">&quot;technical_docs.txt&quot;</span><span class="p">)</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">read_file</span><span class="p">()</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">encode</span><span class="p">,</span> <span class="n">decode</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">ModelConfig</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPTLanguageModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">GPTTrainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="custom-writing-style">
<h4>2. Custom Writing Style<a class="headerlink" href="#custom-writing-style" title="Link to this heading">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train on specific author&#39;s works</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">TextFileProcessor</span><span class="p">(</span><span class="s2">&quot;author_works.txt&quot;</span><span class="p">)</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">read_file</span><span class="p">()</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">encode</span><span class="p">,</span> <span class="n">decode</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">ModelConfig</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPTLanguageModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">GPTTrainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="troubleshooting">
<h3>Troubleshooting<a class="headerlink" href="#troubleshooting" title="Link to this heading">¶</a></h3>
<section id="common-issues-and-solutions">
<h4>Common Issues and Solutions<a class="headerlink" href="#common-issues-and-solutions" title="Link to this heading">¶</a></h4>
<ol class="arabic simple">
<li><p>Out of Memory Errors
* Reduce batch size
* Use gradient checkpointing
* Reduce model size
* Use mixed precision training</p></li>
<li><p>Poor Generation Quality
* Increase training data size
* Adjust temperature and sampling parameters
* Train for more epochs
* Use larger model architecture</p></li>
<li><p>Training Instability
* Adjust learning rate
* Use gradient clipping
* Increase warmup steps
* Check data quality</p></li>
</ol>
</section>
</section>
<section id="getting-help">
<h3>Getting Help<a class="headerlink" href="#getting-help" title="Link to this heading">¶</a></h3>
<p>If you need help:</p>
<ul class="simple">
<li><p>Check the <a class="reference external" href="https://github.com/khushaljethava/createllm/issues">GitHub issues</a></p></li>
<li><p>Open a new issue with:
- Your code
- Error messages
- Expected behavior
- Actual behavior</p></li>
</ul>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">createllm</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, Khushal Jethava.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.1.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="_sources/usage.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>